import pandas as pd
import numpy as np
import xgboost as xgb
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import OrdinalEncoder
from sklearn.impute import SimpleImputer

# âœ… í•œê¸€ í°íŠ¸ ê¹¨ì§ í•´ê²° (Windows/Mac ëŒ€ì‘)
import platform
if platform.system() == "Windows":
    plt.rc("font", family="Malgun Gothic")
else:
    plt.rc("font", family="AppleGothic")

plt.rcParams["axes.unicode_minus"] = False  # ìŒìˆ˜ ê¸°í˜¸ ê¹¨ì§ ë°©ì§€

# -------------- ğŸ“Œ ë°ì´í„° ë¡œë”© --------------
train = pd.read_csv('C:/Users/mch2d/Desktop/LG-Aimers-Data-main/train.csv').drop(columns=['ID'])

# -------------- ğŸ“Œ íƒ€ê²Ÿ ë³€ìˆ˜ ë¶„ë¦¬ --------------
X = train.drop(columns=['ì„ì‹  ì„±ê³µ ì—¬ë¶€'])
y = train['ì„ì‹  ì„±ê³µ ì—¬ë¶€']

# âœ… "ë°°ì•„ ì‚¬ìš©ë¥ " Feature ì¶”ê°€
if "ì´ì‹ëœ ë°°ì•„ ìˆ˜" in X.columns and "ì €ì¥ëœ ë°°ì•„ ìˆ˜" in X.columns:
    X["ë°°ì•„ ì‚¬ìš©ë¥ "] = X["ì´ì‹ëœ ë°°ì•„ ìˆ˜"] / (X["ì´ì‹ëœ ë°°ì•„ ìˆ˜"] + X["ì €ì¥ëœ ë°°ì•„ ìˆ˜"] + 1e-5)

# âœ… "ë¶€ë¶€ ì£¼ ë¶ˆì„ ì›ì¸" ë° "ë¶€ë¶€ ë¶€ ë¶ˆì„ ì›ì¸" Feature ì¶”ê°€
if "ë‚¨ì„± ì£¼ ë¶ˆì„ ì›ì¸" in X.columns and "ì—¬ì„± ì£¼ ë¶ˆì„ ì›ì¸" in X.columns:
    X["ë¶€ë¶€ ì£¼ ë¶ˆì„ ì›ì¸2"] = X["ë‚¨ì„± ì£¼ ë¶ˆì„ ì›ì¸"] | X["ì—¬ì„± ì£¼ ë¶ˆì„ ì›ì¸"]
if "ë‚¨ì„± ë¶€ ë¶ˆì„ ì›ì¸" in X.columns and "ì—¬ì„± ë¶€ ë¶ˆì„ ì›ì¸" in X.columns:
    X["ë¶€ë¶€ ë¶€ ë¶ˆì„ ì›ì¸2"] = X["ë‚¨ì„± ë¶€ ë¶ˆì„ ì›ì¸"] | X["ì—¬ì„± ë¶€ ë¶ˆì„ ì›ì¸"]

# âœ… "ë¯¸ì„¸ì£¼ì… ì„±ê³µë¥ " Feature ì¶”ê°€
X["ë¯¸ì„¸ì£¼ì… ì„±ê³µë¥ "] = X["ë¯¸ì„¸ì£¼ì…ì—ì„œ ìƒì„±ëœ ë°°ì•„ ìˆ˜"] / (X["ë¯¸ì„¸ì£¼ì…ëœ ë‚œì ìˆ˜"] + 1e-5)

# âœ… "ë¯¸ì„¸ì£¼ì… ì´ì‹ìœ¨" Feature ì¶”ê°€
X["ë¯¸ì„¸ì£¼ì… ì´ì‹ìœ¨"] = X["ë¯¸ì„¸ì£¼ì… ë°°ì•„ ì´ì‹ ìˆ˜"] / (X["ë¯¸ì„¸ì£¼ì…ì—ì„œ ìƒì„±ëœ ë°°ì•„ ìˆ˜"] + 1e-5)

# -------------- ğŸ“Œ ê²°ì¸¡ì¹˜ ì²˜ë¦¬ --------------
categorical_columns = X.select_dtypes(include=['object']).columns.tolist()
ordinal_encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)
X[categorical_columns] = ordinal_encoder.fit_transform(X[categorical_columns])

numeric_columns = X.select_dtypes(include=['int64', 'float64']).columns.tolist()
imputer = SimpleImputer(strategy='mean')
X[numeric_columns] = imputer.fit_transform(X[numeric_columns])

# -------------- ğŸ“Œ XGBoost ëª¨ë¸ í•™ìŠµ --------------
params = {
    "objective": "binary:logistic",
    "eval_metric": "logloss",
    "max_depth": 6,
    "learning_rate": 0.03,
    "subsample": 0.8,
    "colsample_bytree": 0.8,
    "random_state": 42
}

dtrain = xgb.DMatrix(X, label=y)

xgb_model = xgb.train(
    params=params,
    dtrain=dtrain,
    num_boost_round=500,
    verbose_eval=False
)

# -------------- ğŸ“Œ Feature Importance ê³„ì‚° --------------
importance_df = pd.DataFrame({
    "Feature": X.columns,
    "Gain": [xgb_model.get_score(importance_type="gain").get(f, 0) for f in X.columns],
    "Weight": [xgb_model.get_score(importance_type="weight").get(f, 0) for f in X.columns],
    "Cover": [xgb_model.get_score(importance_type="cover").get(f, 0) for f in X.columns]
})

# âœ… Feature Importance ì •ë ¬
importance_df = importance_df.sort_values(by="Gain", ascending=False)

# âœ… Gain ê°’ í•˜ìœ„ 30% ê¸°ì¤€ìœ¼ë¡œ Feature ì„ íƒ
gain_threshold = np.percentile(importance_df["Gain"], 30)  # í•˜ìœ„ 30% ê¸°ì¤€ê°’
low_gain_features = importance_df[importance_df["Gain"] <= gain_threshold]
high_gain_features = importance_df[importance_df["Gain"] > gain_threshold]

# âœ… Gain ê°’ ë¶„í¬ ì‹œê°í™” (ë§‰ëŒ€ ê·¸ë˜í”„)
plt.figure(figsize=(14, 6))
barplot = sns.barplot(x="Gain", y="Feature", data=importance_df, palette="coolwarm", hue=None, legend=False)
plt.xlabel("Gain ê°’")
plt.ylabel("Feature ì´ë¦„")
plt.title("Feature Gain ê°’ ë¶„í¬")

# ğŸ”´ í•˜ìœ„ 30% Featureì— ë¹¨ê°„ìƒ‰ ê°•ì¡°
for index, patch in enumerate(barplot.patches):
    if importance_df["Feature"].iloc[index] in low_gain_features["Feature"].values:
        patch.set_color("red")

# í•˜ìœ„ 30% ê¸°ì¤€ì„  ì¶”ê°€
plt.axvline(gain_threshold, color="black", linestyle="--", label=f"í•˜ìœ„ 30% ê¸°ì¤€ ({gain_threshold:.2f})")
plt.legend()
plt.grid(axis="x")
plt.show()

# âœ… Feature ê°„ ìƒê´€ê´€ê³„ ë¶„ì„ (Gain ë‚®ì€ Featureë“¤ë§Œ ì„ íƒ)
low_gain_feature_names = low_gain_features["Feature"].tolist()

# âœ… ìƒê´€ê´€ê³„ íˆíŠ¸ë§µ ì‹œê°í™” (í•˜ìœ„ 30% Featureë§Œ)
if len(low_gain_feature_names) > 1:  # Featureê°€ 2ê°œ ì´ìƒì¼ ê²½ìš°ë§Œ ì‹¤í–‰
    plt.figure(figsize=(12, 10))
    sns.heatmap(X[low_gain_feature_names].corr(), annot=True, cmap="coolwarm", fmt=".2f", linewidths=0.5)
    plt.title("Gain ë‚®ì€ Feature ê°„ ìƒê´€ê´€ê³„ íˆíŠ¸ë§µ")
    plt.show()

# âœ… Feature Importance ìƒì„¸ ì¶œë ¥
print("\nğŸ”¥ ì „ì²´ Feature Importance (Gain, Weight, Cover ê°’ í¬í•¨):")
print(importance_df.to_string(index=False))  # ì „ì²´ Feature Importance í…Œì´ë¸” ì¶œë ¥

# âœ… ê²°ê³¼ ì¶œë ¥
print(f"\nğŸ” Gain í•˜ìœ„ 30% (â‰¤ {gain_threshold:.2f}) Feature ê°œìˆ˜: {len(low_gain_features)}")
print(f"ğŸ“Œ í•´ë‹¹ Feature ëª©ë¡: {low_gain_features['Feature'].tolist()}")

print(f"\nğŸ”¥ Gain ìƒìœ„ 70% (> {gain_threshold:.2f}) Feature ê°œìˆ˜: {len(high_gain_features)}")
print(f"ğŸ“Œ í•´ë‹¹ Feature ëª©ë¡: {high_gain_features['Feature'].tolist()}")
