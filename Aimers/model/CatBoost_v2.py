import numpy as np
import pandas as pd
import optuna
import pickle
from catboost import CatBoostClassifier
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import roc_auc_score

# ðŸš€ **1. ë°ì´í„° ë¡œë“œ**
train_path = "C:/Users/mch2d/Desktop/LG-Aimers-Data-main/train.csv"
test_path = "C:/Users/mch2d/Desktop/LG-Aimers-Data-main/test.csv"
submission_path = "C:/Users/mch2d/Desktop/LG-Aimers-Data-main/sample_submission.csv"

df_train = pd.read_csv(train_path)
df_test = pd.read_csv(test_path)
df_sample_submission = pd.read_csv(submission_path)

# ðŸ“Œ **2. ID ì»¬ëŸ¼ ì €ìž¥**
test_ids = df_sample_submission["ID"]

# ðŸŽ¯ **3. íƒ€ê²Ÿ ë³€ìˆ˜ ë¶„ë¦¬**
target = "ìž„ì‹  ì„±ê³µ ì—¬ë¶€"
X = df_train.drop(columns=["ID", target], errors="ignore")
y = df_train[target]

# ðŸ”¥ **4. íŽ¸í–¥ëœ ì»¬ëŸ¼ ì œê±°**
biased_cols = [
    "ì‹ ì„  ë°°ì•„ ì‚¬ìš© ì—¬ë¶€", "ë¯¸ì„¸ì£¼ìž…ëœ ë‚œìž ìˆ˜", "IVF ì‹œìˆ  íšŸìˆ˜",
    "IVF ìž„ì‹  íšŸìˆ˜", "ì´ ì¶œì‚° íšŸìˆ˜", "ì •ìž ì¶œì²˜"
]

threshold = 0.95
biased_cols += [col for col in X.columns if X[col].value_counts(normalize=True).max() >= threshold]

X.drop(columns=biased_cols, inplace=True, errors="ignore")
df_test.drop(columns=biased_cols, inplace=True, errors="ignore")

# ðŸ› ï¸ **5. ê²°ì¸¡ì¹˜ ì²˜ë¦¬**
missing_ratio = (X.isnull().sum() / len(X)) * 100

# ðŸŽ­ 80% ì´ìƒ ê²°ì¸¡ -> ì»¬ëŸ¼ ì‚­ì œ
to_drop = missing_ratio[missing_ratio >= 80].index.tolist()
X.drop(columns=to_drop, inplace=True, errors="ignore")
df_test.drop(columns=to_drop, inplace=True, errors="ignore")

# ðŸŽ¯ 15%~30% ê²°ì¸¡ -> í‰ê· ê°’ ëŒ€ì²´
to_fill_mean = missing_ratio[(missing_ratio >= 15) & (missing_ratio < 30)].index.tolist()
X[to_fill_mean] = X[to_fill_mean].fillna(X[to_fill_mean].mean())
df_test[to_fill_mean] = df_test[to_fill_mean].fillna(X[to_fill_mean].mean())

# ðŸ”¹ **6. ë²”ì£¼í˜• ë°ì´í„° í™•ì¸ & ì •ë¦¬**
categorical_features = X.select_dtypes(include=["object"]).columns.tolist()

# ðŸ”¥ í…ŒìŠ¤íŠ¸ ë°ì´í„° ì»¬ëŸ¼ ë§žì¶”ê¸°
df_test = df_test.reindex(columns=X.columns, fill_value=0)

# ðŸ·ï¸ **ë²”ì£¼í˜• ë³€ìˆ˜ ê²°ì¸¡ì¹˜ëŠ” ìµœë¹ˆê°’(Mode)ìœ¼ë¡œ ëŒ€ì²´**
for col in categorical_features:
    most_frequent = X[col].mode()[0]  # ìµœë¹ˆê°’ ì°¾ê¸°
    X[col] = X[col].fillna(most_frequent).astype(str)
    df_test[col] = df_test[col].fillna(most_frequent).astype(str)

# âš–ï¸ **7. í´ëž˜ìŠ¤ ê°€ì¤‘ì¹˜ ì„¤ì •**
weights = {0: 0.25, 1: 0.75}  # ì‹¤íŒ¨(0): 0.25, ì„±ê³µ(1): 0.75

# ðŸŽ¯ **8. Optunaë¥¼ í™œìš©í•œ í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”**
def objective(trial):
    config = {
        "iterations": trial.suggest_int("iterations", 500, 3000),
        "depth": trial.suggest_int("depth", 4, 10),
        "learning_rate": trial.suggest_float("learning_rate", 0.005, 0.1, log=True),
        "l2_leaf_reg": trial.suggest_float("l2_leaf_reg", 1.0, 50.0, log=True),
        "border_count": trial.suggest_int("border_count", 16, 64),
        "grow_policy": trial.suggest_categorical("grow_policy", ["SymmetricTree", "Lossguide", "Depthwise"]),
        "class_weights": [weights[0], weights[1]],
        "random_seed": 42,
        "eval_metric": "AUC",
        "loss_function": "Logloss",
        "task_type": "GPU",
        "devices": "0",
        "verbose": 0  # ðŸ”¥ í•™ìŠµ ê³¼ì • ì¶œë ¥ ì œê±°
    }
    
    kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
    auc_scores = []
    
    for train_idx, valid_idx in kfold.split(X, y):
        X_train, X_valid = X.iloc[train_idx], X.iloc[valid_idx]
        y_train, y_valid = y.iloc[train_idx], y.iloc[valid_idx]

        model = CatBoostClassifier(**config)
        model.fit(
            X_train, y_train,
            eval_set=(X_valid, y_valid),
            cat_features=categorical_features,
            early_stopping_rounds=100,
            verbose=0  # ðŸ”¥ ì¶œë ¥ ì œê±°
        )
        
        valid_preds = model.predict_proba(X_valid)[:, 1]
        auc_scores.append(roc_auc_score(y_valid, valid_preds))
    
    return np.mean(auc_scores)

# ðŸš€ **9. Optuna ì‹¤í–‰ (í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”)**
study = optuna.create_study(direction="maximize")
study.optimize(objective, n_trials=50)

# ðŸ’¾ **10. ìµœì  íŒŒë¼ë¯¸í„° ì €ìž¥**
best_config = study.best_params
best_config.update({
    "random_seed": 42,
    "eval_metric": "AUC",
    "loss_function": "Logloss",
    "task_type": "GPU",
    "devices": "0",
    "verbose": 0  # ðŸ”¥ ì¶œë ¥ ì œê±°
})

# ðŸ”¥ GPU ë¶ˆí•„ìš” íŒŒë¼ë¯¸í„° ì œê±°
if "colsample_bylevel" in best_config:
    del best_config["colsample_bylevel"]

# ðŸ“‚ **ìµœì í™”ëœ íŒŒë¼ë¯¸í„° ì €ìž¥**
param_path = "best_catboost_params.pkl"
with open(param_path, "wb") as f:
    pickle.dump(best_config, f)

print(f"ðŸ“ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì €ìž¥ ì™„ë£Œ: {param_path}")
print(f"ðŸŽ¯ ìµœì ì˜ íŒŒë¼ë¯¸í„°: {best_config}")

# ðŸ† **11. ìµœì  ëª¨ë¸ í•™ìŠµ**
best_config["class_weights"] = [weights[0], weights[1]]

try:
    print("ðŸš€ ëª¨ë¸ í•™ìŠµ ì‹œìž‘...")
    best_model = CatBoostClassifier(**best_config)
    best_model.fit(
        X, y,
        cat_features=categorical_features,
        verbose=0  # ðŸ”¥ ìµœì¢… í•™ìŠµ ê³¼ì • ì¶œë ¥ ì œê±°
    )

    # ðŸ”Ž **12. í…ŒìŠ¤íŠ¸ ë°ì´í„° ì˜ˆì¸¡**
    X_test = df_test
    predictions = best_model.predict_proba(X_test)[:, 1]

    # ðŸ“ **13. sample_submission ìƒì„±**
    submission = pd.DataFrame({"ID": test_ids, "probability": predictions})

    # ðŸ’¾ **14. ìµœì¢… CSV ì €ìž¥**
    final_csv_path = "C:/Users/mch2d/Desktop/LG-Aimers-Data-main/catboost_final_submission.csv"
    submission.to_csv(final_csv_path, index=False)

    print(f"âœ… ì˜ˆì¸¡ ê²°ê³¼ ì €ìž¥ ì™„ë£Œ: {final_csv_path}")

except Exception as e:
    print(f"âŒ ëª¨ë¸ í•™ìŠµ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
