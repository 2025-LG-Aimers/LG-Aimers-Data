import numpy as np
import pandas as pd
import pickle
from catboost import CatBoostClassifier
from sklearn.model_selection import train_test_split
from sklearn.calibration import CalibratedClassifierCV
from sklearn.metrics import roc_auc_score, accuracy_score

# âœ… ë°ì´í„° ë¡œë“œ
train_path = "C:/Users/mch2d/Desktop/LG-Aimers-Data-main/train.csv"
test_path = "C:/Users/mch2d/Desktop/LG-Aimers-Data-main/test.csv"
submission_path = "C:/Users/mch2d/Desktop/LG-Aimers-Data-main/sample_submission.csv"
param_path = "C:/Users/mch2d/Desktop/LG-Aimers-Data-main/Params/best_catboost_params.pkl"

df_train = pd.read_csv(train_path)
df_test = pd.read_csv(test_path)
df_sample_submission = pd.read_csv(submission_path)

# âœ… ID ì»¬ëŸ¼ ì €ìž¥
test_ids = df_sample_submission["ID"]

# âœ… íƒ€ê²Ÿ ë³€ìˆ˜ ë¶„ë¦¬
target = "ìž„ì‹  ì„±ê³µ ì—¬ë¶€"
X = df_train.drop(columns=["ID", target], errors="ignore")
y = df_train[target]

# âœ… íŽ¸í–¥ëœ ì»¬ëŸ¼ ì œê±°
biased_cols = [
    "ì‹ ì„  ë°°ì•„ ì‚¬ìš© ì—¬ë¶€", "ë¯¸ì„¸ì£¼ìž…ëœ ë‚œìž ìˆ˜", "í˜¼í•©ëœ ë‚œìž ìˆ˜", "IVF ì‹œìˆ  íšŸìˆ˜",
    "IVF ìž„ì‹  íšŸìˆ˜", "ì´ ì¶œì‚° íšŸìˆ˜", "ì •ìž ì¶œì²˜"
]
threshold = 0.95
biased_cols += [col for col in X.columns if X[col].value_counts(normalize=True).max() >= threshold]

X.drop(columns=biased_cols, inplace=True, errors="ignore")
df_test.drop(columns=biased_cols, inplace=True, errors="ignore")

# âœ… ê²°ì¸¡ì¹˜ ì²˜ë¦¬
missing_ratio = (X.isnull().sum() / len(X)) * 100

# 80% ì´ìƒ ê²°ì¸¡ -> ì»¬ëŸ¼ ì‚­ì œ
to_drop = missing_ratio[missing_ratio >= 80].index.tolist()
X.drop(columns=to_drop, inplace=True, errors="ignore")
df_test.drop(columns=to_drop, inplace=True, errors="ignore")

# 15%~30% ê²°ì¸¡ -> í‰ê· ê°’ ëŒ€ì²´
to_fill_mean = missing_ratio[(missing_ratio >= 15) & (missing_ratio < 30)].index.tolist()
X[to_fill_mean] = X[to_fill_mean].fillna(X[to_fill_mean].mean())
df_test[to_fill_mean] = df_test[to_fill_mean].fillna(X[to_fill_mean].mean())

# âœ… ë²”ì£¼í˜• ë°ì´í„° í™•ì¸ & ì •ë¦¬
categorical_features = X.select_dtypes(include=["object"]).columns.tolist()

# âœ… ëª¨ë“  ë²”ì£¼í˜• ë³€ìˆ˜ë¥¼ ë¬¸ìžì—´(str)ë¡œ ë³€í™˜ (CatBoostê°€ ì¸ì‹í•˜ë„ë¡)
for col in categorical_features:
    X[col] = X[col].astype(str)
    df_test[col] = df_test[col].astype(str)

# í…ŒìŠ¤íŠ¸ ë°ì´í„° ì»¬ëŸ¼ ë§žì¶”ê¸°
df_test = df_test.reindex(columns=X.columns, fill_value=0)

# âœ… ì €ìž¥ëœ ìµœì ì˜ íŒŒë¼ë¯¸í„° ë¡œë“œ
try:
    with open(param_path, "rb") as f:
        best_config = pickle.load(f)
    print(f"âœ… ìµœì ì˜ í•˜ì´í¼íŒŒë¼ë¯¸í„° ë¡œë“œ ì™„ë£Œ: {best_config}")
except Exception as e:
    print(f"âŒ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
    exit()

# âœ… GPU ì‚¬ìš© ì‹œ AUC ì§€ì› ë¬¸ì œ í•´ê²° (Loglossë¡œ ë³€ê²½)
if best_config.get("task_type") == "GPU":
    best_config["eval_metric"] = "Logloss"

# âœ… 8:2ë¡œ ë°ì´í„° ë¶„í•  (Stratify ì‚¬ìš©í•˜ì—¬ í´ëž˜ìŠ¤ ë¹„ìœ¨ ìœ ì§€)
X_train, X_valid, y_train, y_valid = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

print(f"ðŸ“Š í›ˆë ¨ ë°ì´í„° í¬ê¸°: {X_train.shape}, ê²€ì¦ ë°ì´í„° í¬ê¸°: {X_valid.shape}")

# âœ… CatBoost ëª¨ë¸ í•™ìŠµ
best_config.pop("verbose", None)  # verbose ì œê±°
best_model = CatBoostClassifier(**best_config, verbose=0)

print("ðŸš€ ëª¨ë¸ í•™ìŠµ ì‹œìž‘...")
best_model.fit(X_train, y_train, cat_features=categorical_features)

# âœ… ê²€ì¦ ë°ì´í„° ì˜ˆì¸¡ (í™•ë¥  ì˜ˆì¸¡)
valid_probs = best_model.predict_proba(X_valid)[:, 1]
valid_auc = roc_auc_score(y_valid, valid_probs)

# âœ… ê²€ì¦ ë°ì´í„° ì˜ˆì¸¡ (í´ëž˜ìŠ¤ ì˜ˆì¸¡)
valid_preds = best_model.predict(X_valid)
valid_acc = accuracy_score(y_valid, valid_preds)

print(f"âœ… ëª¨ë¸ í‰ê°€ ì™„ë£Œ! AUC: {valid_auc:.10f} | Accuracy: {valid_acc:.10f}")

# âœ… í›„ì²˜ë¦¬ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ (Platt Scaling) ì ìš©
cal_model = CalibratedClassifierCV(best_model, method="sigmoid", cv="prefit")
cal_model.fit(X_valid.values, y_valid)

# âœ… ìº˜ë¦¬ë¸Œë ˆì´ì…˜ í›„ ê²€ì¦ ë°ì´í„° ì˜ˆì¸¡ (í™•ë¥  ì˜ˆì¸¡)
valid_calibrated_probs = cal_model.predict_proba(X_valid.values)[:, 1]
valid_calibrated_auc = roc_auc_score(y_valid, valid_calibrated_probs)

# âœ… ìº˜ë¦¬ë¸Œë ˆì´ì…˜ í›„ ê²€ì¦ ë°ì´í„° ì˜ˆì¸¡ (í´ëž˜ìŠ¤ ì˜ˆì¸¡)
valid_calibrated_preds = cal_model.predict(X_valid.values)
valid_calibrated_acc = accuracy_score(y_valid, valid_calibrated_preds)

print(f"ðŸŽ¯ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ í›„ í‰ê°€! AUC: {valid_calibrated_auc:.10f} | Accuracy: {valid_calibrated_acc:.10f}")

# âœ… í…ŒìŠ¤íŠ¸ ë°ì´í„° ì˜ˆì¸¡
test_preds = best_model.predict_proba(df_test)[:, 1]
calibrated_test_preds = cal_model.predict_proba(df_test.values)[:, 1]

# âœ… sample_submission ìƒì„±
submission_raw = pd.DataFrame({"ID": test_ids, "probability": test_preds})
submission_calibrated = pd.DataFrame({"ID": test_ids, "probability": calibrated_test_preds})

# âœ… ìµœì¢… CSV ì €ìž¥
raw_csv_path = "C:/Users/mch2d/Desktop/LG-Aimers-Data-main/catboost_final_submission_raw.csv"
calibrated_csv_path = "C:/Users/mch2d/Desktop/LG-Aimers-Data-main/catboost_final_submission_calibrated.csv"

submission_raw.to_csv(raw_csv_path, index=False)
submission_calibrated.to_csv(calibrated_csv_path, index=False)

print(f"âœ… ì›ë³¸ ëª¨ë¸ ì˜ˆì¸¡ ê²°ê³¼ ì €ìž¥ ì™„ë£Œ: {raw_csv_path}")
print(f"âœ… ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì ìš© ëª¨ë¸ ì˜ˆì¸¡ ê²°ê³¼ ì €ìž¥ ì™„ë£Œ: {calibrated_csv_path}")
