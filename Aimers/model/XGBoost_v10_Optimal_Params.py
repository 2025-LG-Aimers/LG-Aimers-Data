import numpy as np
import pandas as pd
import optuna
import pickle
import xgboost as xgb
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import roc_auc_score
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import OrdinalEncoder

# âœ… ë°ì´í„° ë¡œë“œ
file_path_train = "C:/Users/ANTL/Documents/GitHub/LG-Aimers-Data/train.csv"
file_path_test = "C:/Users/ANTL/Documents/GitHub/LG-Aimers-Data/test.csv"
sample_submission_path = "C:/Users/ANTL/Documents/GitHub/LG-Aimers-Data/sample_submission.csv"

df_train = pd.read_csv(file_path_train)
df_test = pd.read_csv(file_path_test)
df_sample_submission = pd.read_csv(sample_submission_path)

# âœ… ID ì»¬ëŸ¼ ì €ì¥
test_ids = df_sample_submission["ID"]

# âœ… íƒ€ê²Ÿ ë³€ìˆ˜ ë¶„ë¦¬
target_col = "ì„ì‹  ì„±ê³µ ì—¬ë¶€"
X = df_train.drop(columns=["ID", target_col], errors="ignore")
y = df_train[target_col]

# âœ… í¸í–¥ëœ ì»¬ëŸ¼ ì œê±°
columns_to_remove = [
    "ì‹ ì„  ë°°ì•„ ì‚¬ìš© ì—¬ë¶€", "ë¯¸ì„¸ì£¼ì…ëœ ë‚œì ìˆ˜", 
    "IVF ì‹œìˆ  íšŸìˆ˜", "IVF ì„ì‹  íšŸìˆ˜", "ì´ ì¶œì‚° íšŸìˆ˜", "ì •ì ì¶œì²˜", " ë°°ë€ ìê·¹ ì—¬ë¶€"
]
threshold = 0.95
biased_columns = [col for col in X.columns if X[col].value_counts(normalize=True).max() >= threshold]
columns_to_remove.extend(biased_columns)

X.drop(columns=columns_to_remove, inplace=True, errors="ignore")
df_test.drop(columns=columns_to_remove, inplace=True, errors="ignore")

# âœ… ê²°ì¸¡ì¹˜ ì²˜ë¦¬
missing_percentage = (X.isnull().sum() / len(X)) * 100

# âœ… 1. ê²°ì¸¡ì¹˜ ë¹„ìœ¨ì´ 80% ì´ìƒì¸ ì»¬ëŸ¼ ì‚­ì œ
high_missing_columns = missing_percentage[missing_percentage >= 80].index
X.drop(columns=high_missing_columns, inplace=True, errors="ignore")
df_test.drop(columns=high_missing_columns, inplace=True, errors="ignore")

# âœ… 2. ê²°ì¸¡ì¹˜ ë¹„ìœ¨ì´ 15% ~ 30%ì¸ ì»¬ëŸ¼ í‰ê· ê°’ìœ¼ë¡œ ëŒ€ì²´
mid_missing_columns = missing_percentage[(missing_percentage >= 15) & (missing_percentage < 30)].index
imputer = SimpleImputer(strategy="mean")  # í‰ê· ê°’ ëŒ€ì²´
X[mid_missing_columns] = imputer.fit_transform(X[mid_missing_columns])
df_test[mid_missing_columns] = imputer.transform(df_test[mid_missing_columns])

# âœ… 3. ë²”ì£¼í˜• ì»¬ëŸ¼ ìë™ ê°ì§€ & ì¸ì½”ë”© (Ordinal Encoding)
categorical_columns = X.select_dtypes(include=["object"]).columns.tolist()
ordinal_encoder = OrdinalEncoder(handle_unknown="use_encoded_value", unknown_value=-1)
X[categorical_columns] = ordinal_encoder.fit_transform(X[categorical_columns])
df_test[categorical_columns] = ordinal_encoder.transform(df_test[categorical_columns])

# âœ… XGBoost Optuna ìµœì í™” (K-Fold êµì°¨ ê²€ì¦ ì ìš©)
def objective(trial):
    params = {
        "objective": "binary:logistic",
        "eval_metric": "auc",
        "max_depth": trial.suggest_int("max_depth", 3, 10),
        "learning_rate": trial.suggest_float("learning_rate", 0.01, 0.3, log=True),
        "n_estimators": trial.suggest_int("n_estimators", 100, 1000),
        "subsample": trial.suggest_float("subsample", 0.5, 1.0),
        "colsample_bytree": trial.suggest_float("colsample_bytree", 0.5, 1.0),
        "reg_alpha": trial.suggest_float("reg_alpha", 0.0, 10.0),
        "reg_lambda": trial.suggest_float("reg_lambda", 0.0, 10.0),
        "random_state": 42,
        "use_label_encoder": False
    }
    
    kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
    auc_scores = []
    
    for train_idx, valid_idx in kf.split(X, y):
        X_train, X_valid = X.iloc[train_idx], X.iloc[valid_idx]
        y_train, y_valid = y.iloc[train_idx], y.iloc[valid_idx]

        dtrain = xgb.DMatrix(X_train, label=y_train)
        dvalid = xgb.DMatrix(X_valid, label=y_valid)

        model = xgb.train(params, dtrain, num_boost_round=500, evals=[(dvalid, "valid")], early_stopping_rounds=50, verbose_eval=False)

        valid_preds = model.predict(dvalid)
        auc_scores.append(roc_auc_score(y_valid, valid_preds))

    return np.mean(auc_scores)

# âœ… Optuna ì‹¤í–‰ (ìµœì í™”)
study = optuna.create_study(direction="maximize")
study.optimize(objective, n_trials=30)

# âœ… ìµœì  íŒŒë¼ë¯¸í„° ì €ì¥ (`pkl` íŒŒì¼)
best_params = study.best_params
best_params["random_state"] = 42
best_params["eval_metric"] = "auc"
best_params["objective"] = "binary:logistic"
best_params["use_label_encoder"] = False

# âœ… ìµœì í™”ëœ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì €ì¥
params_save_path = "best_xgboost_params.pkl"
with open(params_save_path, "wb") as f:
    pickle.dump(best_params, f)

print(f"ğŸ“ ìµœì í™”ëœ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì €ì¥ ì™„ë£Œ: {params_save_path}")
print(f"ğŸ¯ ìµœì ì˜ í•˜ì´í¼íŒŒë¼ë¯¸í„°: {best_params}")

# âœ… ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¡œ ì „ì²´ ë°ì´í„° í•™ìŠµ
dtrain = xgb.DMatrix(X, label=y)
final_model = xgb.train(best_params, dtrain, num_boost_round=500, verbose_eval=True)

# âœ… í…ŒìŠ¤íŠ¸ ë°ì´í„° ì˜ˆì¸¡
dtest = xgb.DMatrix(df_test)
test_pred_proba = final_model.predict(dtest)

# âœ… sample_submission í˜•ì‹ìœ¼ë¡œ ë³€í™˜
df_submission = pd.DataFrame({"ID": test_ids, "probability": test_pred_proba})

# âœ… ìµœì¢… CSV ì €ì¥
submission_file_path = "C:/Users/ANTL/Documents/GitHub/LG-Aimers-Data/XGBoost_Optuna_KFold.csv"
df_submission.to_csv(submission_file_path, index=False)

print(f"âœ… ìµœì í™”ëœ XGBoost ëª¨ë¸ì˜ ì˜ˆì¸¡ ê²°ê³¼ê°€ '{submission_file_path}' ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
