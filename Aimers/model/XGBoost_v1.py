import pandas as pd
import numpy as np
import xgboost as xgb
from sklearn.model_selection import StratifiedKFold
from sklearn.preprocessing import OrdinalEncoder
from sklearn.impute import SimpleImputer
from sklearn.metrics import roc_auc_score, accuracy_score

# -------------- ğŸ“Œ ë°ì´í„° ë¡œë”© --------------
train = pd.read_csv('C:/Users/ANTL/Documents/GitHub/LG-Aimers-Data/train.csv').drop(columns=['ID'])
test = pd.read_csv('C:/Users/ANTL/Documents/GitHub/LG-Aimers-Data/test.csv').drop(columns=['ID'])

# -------------- ğŸ“Œ íƒ€ê²Ÿ ë³€ìˆ˜ ë¶„ë¦¬ --------------
X = train.drop(columns=['ì„ì‹  ì„±ê³µ ì—¬ë¶€'])  # ì…ë ¥ ë°ì´í„° (Feature)
y = train['ì„ì‹  ì„±ê³µ ì—¬ë¶€']  # íƒ€ê²Ÿ ë³€ìˆ˜ (Label)

# âœ… 1. í¸í–¥ëœ ì»¬ëŸ¼ ì œê±°
columns_to_remove = ["ì‹ ì„  ë°°ì•„ ì‚¬ìš© ì—¬ë¶€", "ë¯¸ì„¸ì£¼ì…ëœ ë‚œì ìˆ˜", "IVF ì‹œìˆ  íšŸìˆ˜", 
                     "IVF ì„ì‹  íšŸìˆ˜", "ì´ ì¶œì‚° íšŸìˆ˜", "ì •ì ì¶œì²˜"]

# âœ… 95% ì´ìƒ í¸í–¥ëœ ì»¬ëŸ¼ ì œê±°
threshold = 0.95
biased_columns = [col for col in X.columns if X[col].value_counts(normalize=True).max() >= threshold]
columns_to_remove.extend(biased_columns)

X.drop(columns=columns_to_remove, inplace=True, errors='ignore')
test.drop(columns=columns_to_remove, inplace=True, errors='ignore')

# âœ… 2. ê²°ì¸¡ì¹˜ ì²˜ë¦¬ (ì»¬ëŸ¼ë³„ ê²°ì¸¡ì¹˜ ë¹„ìœ¨ ê³„ì‚°)
missing_percentage = (X.isnull().sum() / len(X)) * 100

# ğŸ”¥ 80% ì´ìƒ ê²°ì¸¡ì¹˜ ì»¬ëŸ¼ ì‚­ì œ
high_missing_columns = missing_percentage[missing_percentage >= 80].index.tolist()
X.drop(columns=high_missing_columns, inplace=True, errors='ignore')
test.drop(columns=high_missing_columns, inplace=True, errors='ignore')

# ğŸ”¥ 15% ~ 30% ê²°ì¸¡ì¹˜ í‰ê· ê°’ìœ¼ë¡œ ëŒ€ì²´
mid_missing_columns = missing_percentage[(missing_percentage >= 10) & (missing_percentage < 50)].index.tolist()
imputer = SimpleImputer(strategy='mean')
X[mid_missing_columns] = imputer.fit_transform(X[mid_missing_columns])
test[mid_missing_columns] = imputer.transform(test[mid_missing_columns])

# âœ… 3. ì œê±°ë˜ì§€ë„ ì•Šê³  ê²°ì¸¡ì¹˜ë„ ëŒ€ì²´ë˜ì§€ ì•Šì€ ì»¬ëŸ¼ ì°¾ê¸°
remaining_columns = list(set(X.columns) - set(mid_missing_columns))

# âœ… 4. ìµœì¢… ì¶œë ¥
print("\nğŸ”¥ [ì œê±°ëœ ì»¬ëŸ¼ ëª©ë¡]")
print(f"âœ… í¸í–¥ëœ ì»¬ëŸ¼: {biased_columns}")
print(f"âœ… 80% ì´ìƒ ê²°ì¸¡ì¹˜ ì»¬ëŸ¼: {high_missing_columns}")
print(f"ğŸ”¥ ìµœì¢… ì œê±°ëœ ì»¬ëŸ¼: {columns_to_remove + high_missing_columns}")

print("\nğŸ”¥ [ê²°ì¸¡ì¹˜ë¥¼ í‰ê· ê°’ìœ¼ë¡œ ëŒ€ì²´í•œ ì»¬ëŸ¼]")
print(mid_missing_columns)

print("\nğŸ”¥ [ì œê±°ë˜ì§€ë„ ì•Šê³  ê²°ì¸¡ì¹˜ë¥¼ ëŒ€ì²´í•˜ì§€ë„ ì•Šì€ ì»¬ëŸ¼]")
print(remaining_columns)
