import pandas as pd
import numpy as np
import xgboost as xgb  # âœ… XGBoost ì „ì²´ ëª¨ë“ˆ ì‚¬ìš©
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OrdinalEncoder
from sklearn.impute import SimpleImputer  # âœ… ê²°ì¸¡ì¹˜ í‰ê·  ëŒ€ì²´ ì¶”ê°€
from sklearn.metrics import roc_auc_score, accuracy_score  # âœ… Accuracy Score ì¶”ê°€

# -------------- ğŸ“Œ ë°ì´í„° ë¡œë”© --------------
train = pd.read_csv('C:/Users/ANTL/Documents/GitHub/LG-Aimers-Data/train.csv').drop(columns=['ID'])
test = pd.read_csv('C:/Users/ANTL/Documents/GitHub/LG-Aimers-Data/test.csv').drop(columns=['ID'])

# -------------- ğŸ“Œ íƒ€ê²Ÿ ë³€ìˆ˜ ë¶„ë¦¬ --------------
X = train.drop(columns=['ì„ì‹  ì„±ê³µ ì—¬ë¶€'])  # ì…ë ¥ ë°ì´í„° (Feature)
y = train['ì„ì‹  ì„±ê³µ ì—¬ë¶€']  # íƒ€ê²Ÿ ë³€ìˆ˜ (Label)

# âœ… 1. "ì´ ìƒì„± ë°°ì•„ ìˆ˜" ì´ìƒì¹˜ ì œê±° (19~51 ë²”ìœ„ ì œê±°)
outlier_feature = "ì´ ìƒì„± ë°°ì•„ ìˆ˜"
outlier_lower, outlier_upper = 19, 51
X = X[(X[outlier_feature] < outlier_lower) | (X[outlier_feature] > outlier_upper)]
y = y.loc[X.index]  # Xì—ì„œ ë°ì´í„°ê°€ ì‚­ì œë˜ì—ˆìœ¼ë¯€ë¡œ, yë„ ë™ì¼í•˜ê²Œ ì¸ë±ìŠ¤ë¥¼ ë§ì¶¤

print(f"âœ… ì´ìƒì¹˜ ì œê±° ì™„ë£Œ: {outlier_feature} {outlier_lower}~{outlier_upper} ì‚¬ì´ ê°’ ì œê±°")
print(f"ğŸ”¹ ì´ìƒì¹˜ ì œê±° í›„ ë°ì´í„° í¬ê¸°: {X.shape}")

# âœ… 2. í•™ìŠµ(80%) - ê²€ì¦(20%) ë°ì´í„° ë¶„í• 
X_train, X_valid, y_train, y_valid = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

print(f"ğŸ”¹ í•™ìŠµ ë°ì´í„° í¬ê¸°: {X_train.shape}, ê²€ì¦ ë°ì´í„° í¬ê¸°: {X_valid.shape}")

# âœ… 3. í¸í–¥ëœ ì»¬ëŸ¼ íƒìƒ‰ & ì œê±° (99% ì´ìƒ í•œ ê°’)
threshold = 0.99
biased_columns = [col for col in X_train.columns if X_train[col].value_counts(normalize=True).max() >= threshold]

X_train.drop(columns=biased_columns, inplace=True, errors='ignore')
X_valid.drop(columns=biased_columns, inplace=True, errors='ignore')
test.drop(columns=biased_columns, inplace=True, errors='ignore')

print(f"âœ… ì œê±°ëœ ì»¬ëŸ¼: {biased_columns}")

# âœ… 4. ê²°ì¸¡ì¹˜ ì²˜ë¦¬ (ìˆ˜ì¹˜í˜• & ë²”ì£¼í˜•)
numeric_columns = X_train.select_dtypes(include=['int64', 'float64']).columns.tolist()

# âœ… 4-1. ìˆ˜ì¹˜í˜• ë°ì´í„° ê²°ì¸¡ì¹˜ í‰ê· ê°’ ëŒ€ì²´
num_imputer = SimpleImputer(strategy='mean')
X_train[numeric_columns] = num_imputer.fit_transform(X_train[numeric_columns])
X_valid[numeric_columns] = num_imputer.transform(X_valid[numeric_columns])
test[numeric_columns] = num_imputer.transform(test[numeric_columns])

# âœ… 4-2. ë²”ì£¼í˜• ë°ì´í„° ê²°ì¸¡ì¹˜ëŠ” "missing"ìœ¼ë¡œ ì±„ìš°ê¸°
categorical_columns = X_train.select_dtypes(include=['object']).columns.tolist()
X_train[categorical_columns] = X_train[categorical_columns].fillna("missing")
X_valid[categorical_columns] = X_valid[categorical_columns].fillna("missing")
test[categorical_columns] = test[categorical_columns].fillna("missing")

# âœ… 5. ë²”ì£¼í˜• ë°ì´í„° Ordinal Encoding ì ìš©
ordinal_encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)
X_train[categorical_columns] = ordinal_encoder.fit_transform(X_train[categorical_columns])
X_valid[categorical_columns] = ordinal_encoder.transform(X_valid[categorical_columns])
test[categorical_columns] = ordinal_encoder.transform(test[categorical_columns])

# -------------- ğŸ“Œ XGBoost ëª¨ë¸ í•™ìŠµ --------------
params = {
    "objective": "binary:logistic",
    "eval_metric": "logloss",
    "max_depth": 6,
    "learning_rate": 0.03,
    "subsample": 0.8,
    "colsample_bytree": 0.8,
    "random_state": 42
}

# âœ… XGBoost DMatrix ìƒì„±
dtrain = xgb.DMatrix(X_train, label=y_train)
dvalid = xgb.DMatrix(X_valid, label=y_valid)

# ğŸ”¥ ëª¨ë¸ í•™ìŠµ (ì¡°ê¸° ì¢…ë£Œ ì ìš©)
watchlist = [(dtrain, "train"), (dvalid, "valid")]
xgb_model = xgb.train(
    params=params,
    dtrain=dtrain,
    num_boost_round=1000,
    evals=watchlist,
    early_stopping_rounds=50,
    verbose_eval=True
)

# -------------- ğŸ“Œ ê²€ì¦ ë°ì´í„°ì—ì„œ ì„±ëŠ¥ í‰ê°€ --------------
valid_pred_proba = xgb_model.predict(dvalid)
valid_pred_class = (valid_pred_proba > 0.5).astype(int)

auc_score = roc_auc_score(y_valid, valid_pred_proba)
accuracy = accuracy_score(y_valid, valid_pred_class)

print(f"ğŸ”¥ ê²€ì¦ ë°ì´í„° ROC-AUC Score: {auc_score:.10f}")
print(f"âœ… ê²€ì¦ ë°ì´í„° Accuracy Score: {accuracy:.10f}")